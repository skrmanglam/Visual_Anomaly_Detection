{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181d9d2f-5a40-4533-be56-16063f915d1b",
   "metadata": {},
   "source": [
    "# Visual Anomly detection\n",
    "\n",
    "Problem Statement:\n",
    "\n",
    "Specific Libs used: Pytorch, Anomlib(Based on Ganomly)\n",
    "\n",
    "Dataset Used: Mvtech AD( Trsisostor class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11d7239-d138-4d31-b3ed-00fb07e107db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting work directory\n",
    "import os\n",
    "\n",
    "work_dir = '/transitor/transitor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "628c5496-51b9-43b3-8105-664f057d2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary libs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import yaml, warnings,math,glob, cv2, random\n",
    "import logging\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7de801-3f28-4476-b6fb-1fe0d58e6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the warning settings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#setting logger settings for debugging\n",
    "logger = logging.getLogger(\"anomalib\")\n",
    "\n",
    "import anomalib\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from anomalib.config import get_configurable_parameters\n",
    "from anomalib.data import get_datamodule\n",
    "from anomalib.models import get_model\n",
    "from anomalib.utils.callbacks import LoadModelCallback, get_callbacks\n",
    "from anomalib.utils.loggers import configure_logger, get_experiment_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "554d9a6c-e68d-4fd6-bd31-62fc110fb15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "11.6\n",
      "8302\n",
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x000001F7568E2370>\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a2cf1-915a-45e7-b139-3b800c137eb1",
   "metadata": {},
   "source": [
    "# Model Config Path\n",
    "\n",
    "Currently, there are **12** anomaly detection models available in `anomalib` library. Namely, \n",
    "\n",
    "- [CFA](https://arxiv.org/abs/2206.04325)\n",
    "- [Patchcore](https://arxiv.org/pdf/2106.08265.pdf)\n",
    "- [Padim](https://arxiv.org/pdf/2011.08785.pdf)\n",
    "- [DFKDE](https://github.com/openvinotoolkit/anomalib/tree/development/anomalib/models/dfkde)\n",
    "- [DFM](https://arxiv.org/pdf/1909.11786.pdf)\n",
    "- [CFlow](https://arxiv.org/pdf/2107.12571v1.pdf)\n",
    "- [Ganomaly](https://arxiv.org/abs/1805.06725)\n",
    "- [STFPM](https://arxiv.org/pdf/2103.04257.pdf)\n",
    "- [FastFlow](https://arxiv.org/abs/2111.07677)\n",
    "- [DREAM](https://arxiv.org/pdf/2108.07610v2.pdf)\n",
    "- [Reverse Distillation](https://arxiv.org/pdf/2201.10703v2.pdf)\n",
    "- [EfficientAD](https://arxiv.org/pdf/2303.14535.pdf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now, let's get their config paths from the respected folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c531c280-2099-40ce-9c93-2240ff93282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATHS = 'C:/Users/skrma/anaconda3/envs/Pytorch/Lib/site-packages/anomalib/models'\n",
    "\n",
    "MODEL_CONFIG_PAIRS = {\n",
    "    'cfa'      :   f'{CONFIG_PATHS}/cfa/config.yaml',\n",
    "    'efficientad': f'{CONFIG_PATHS}/efficientad/config.yaml',\n",
    "    'patchcore':   f'{CONFIG_PATHS}/patchcore/config.yaml',\n",
    "    'padim':       f'{CONFIG_PATHS}/padim/config.yaml',\n",
    "    'cflow':       f'{CONFIG_PATHS}/cflow/config.yaml',\n",
    "    'dfkde':       f'{CONFIG_PATHS}/dfkde/config.yaml',\n",
    "    'dfm':         f'{CONFIG_PATHS}/dfm/config.yaml',\n",
    "    'ganomaly':    f'{CONFIG_PATHS}/ganomaly/config.yaml',\n",
    "    'stfpm':       f'{CONFIG_PATHS}/stfpm/config.yaml',\n",
    "    'fastflow':    f'{CONFIG_PATHS}/fastflow/config.yaml',\n",
    "    'draem':       f'{CONFIG_PATHS}/draem/config.yaml',\n",
    "    'reverse_distillation': f'{CONFIG_PATHS}/reverse_distillation/config.yaml',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "398ada0b-7a20-480c-8001-f5d627bf9687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  name: mvtec\n",
      "  format: mvtec\n",
      "  path: ./datasets/MVTec\n",
      "  category: bottle\n",
      "  task: segmentation\n",
      "  train_batch_size: 1\n",
      "  eval_batch_size: 16\n",
      "  num_workers: 8\n",
      "  image_size: 256 # dimensions to which images are resized (mandatory)\n",
      "  center_crop: null # dimensions to which images are center-cropped after resizing (optional)\n",
      "  normalization: none # data distribution to which the images will be normalized: [none, imagenet]\n",
      "  transform_config:\n",
      "    train: null\n",
      "    eval: null\n",
      "  test_split_mode: from_dir # options: [from_dir, synthetic]\n",
      "  test_split_ratio: 0.2 # fraction of train images held out testing (usage depends on test_split_mode)\n",
      "  val_split_mode: same_as_test # options: [same_as_test, from_test, synthetic]\n",
      "  val_split_ratio: 0.5 # fraction of train/test images held out for validation (usage depends on val_split_mode)\n",
      "\n",
      "model:\n",
      "  name: efficientad\n",
      "  teacher_out_channels: 384\n",
      "  model_size: medium # options: [small, medium]\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.00001\n",
      "  padding: true\n",
      "  # generic params\n",
      "  normalization_method: min_max # options: [null, min_max, cdf]\n",
      "\n",
      "metrics:\n",
      "  image:\n",
      "    - F1Score\n",
      "    - AUROC\n",
      "  pixel:\n",
      "    - F1Score\n",
      "    - AUROC\n",
      "  threshold:\n",
      "    method: adaptive #options: [adaptive, manual]\n",
      "    manual_image: null\n",
      "    manual_pixel: null\n",
      "\n",
      "visualization:\n",
      "  show_images: False # show images on the screen\n",
      "  save_images: True # save images to the file system\n",
      "  log_images: False # log images to the available loggers (if any)\n",
      "  image_save_path: null # path to which images will be saved\n",
      "  mode: full # options: [\"full\", \"simple\"]\n",
      "\n",
      "project:\n",
      "  seed: 42\n",
      "  path: ./results\n",
      "\n",
      "logging:\n",
      "  logger: [] # options: [comet, tensorboard, wandb, csv] or combinations.\n",
      "  log_graph: false # Logs the model graph to respective logger.\n",
      "\n",
      "optimization:\n",
      "  export_mode: null # options: torch, onnx, openvino\n",
      "# PL Trainer Args. Don't add extra parameter here.\n",
      "trainer:\n",
      "  enable_checkpointing: true\n",
      "  default_root_dir: null\n",
      "  gradient_clip_val: 0\n",
      "  gradient_clip_algorithm: norm\n",
      "  num_nodes: 1\n",
      "  devices: 1\n",
      "  enable_progress_bar: true\n",
      "  overfit_batches: 0.0\n",
      "  track_grad_norm: -1\n",
      "  check_val_every_n_epoch: 1\n",
      "  fast_dev_run: false\n",
      "  accumulate_grad_batches: 1\n",
      "  max_epochs: 200\n",
      "  min_epochs: null\n",
      "  max_steps: -1\n",
      "  min_steps: null\n",
      "  max_time: null\n",
      "  limit_train_batches: 1.0\n",
      "  limit_val_batches: 1.0\n",
      "  limit_test_batches: 1.0\n",
      "  limit_predict_batches: 1.0\n",
      "  val_check_interval: 1.0\n",
      "  log_every_n_steps: 50\n",
      "  accelerator: auto # <\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">\n",
      "  strategy: null\n",
      "  sync_batchnorm: false\n",
      "  precision: 32\n",
      "  enable_model_summary: true\n",
      "  num_sanity_val_steps: 0\n",
      "  profiler: null\n",
      "  benchmark: false\n",
      "  deterministic: false\n",
      "  reload_dataloaders_every_n_epochs: 0\n",
      "  auto_lr_find: false\n",
      "  replace_sampler_ddp: true\n",
      "  detect_anomaly: false\n",
      "  auto_scale_batch_size: false\n",
      "  plugins: null\n",
      "  move_metrics_to_cpu: false\n",
      "  multiple_trainloader_mode: max_size_cycle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'efficientad' \n",
    "\n",
    "print(open(os.path.join(MODEL_CONFIG_PAIRS[MODEL]), 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8ea585-9f23-456d-b53a-ea3d2fb646c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update config\n",
    "\n",
    "new_update = {\n",
    "    \"path\" : '/transitor/transitor',\n",
    "    \"category\" : 'transistor',\n",
    "    \"image_size\" : 256,\n",
    "    \"train_batch_size\": 48,\n",
    "    \"seed\" : 101\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38874322-4583-429c-b84a-e7070a4acef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update yaml key's value\n",
    "\n",
    "def update_yaml (old_yaml, new_yaml, new_update):\n",
    "    # load yaml\n",
    "    with open (old_yaml) as f:\n",
    "        old = yaml.safe_load(f)\n",
    "        \n",
    "    temp = []\n",
    "    def set_state(old, key, value):\n",
    "        if isinstance(old, dict):\n",
    "            for k, v in old.items():\n",
    "                if k == 'project':\n",
    "                    temp.append(k)\n",
    "                if k == key:\n",
    "                    if temp and k == 'path':\n",
    "                        # right now not altering 'project.path' configuration\n",
    "                        continue\n",
    "                    old[k] = value\n",
    "                elif isinstance(v, dict):\n",
    "                    set_state(v, key, value)\n",
    "                    \n",
    "    # iterate over the new update key-value pair\n",
    "    for key, value in new_update.items():\n",
    "        set_state(old, key, value)\n",
    "        \n",
    "    #save the updated/ modified yaml file\n",
    "    with open(new_yaml, 'w') as f:\n",
    "        yaml.safe_dump(old, f, default_flow_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f111854-e089-4015-8892-2bfcc0464d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a new path locartion of new config file\n",
    "new_yaml_path = CONFIG_PATHS + '/' + list(MODEL_CONFIG_PAIRS.keys())[0] + '_new.yaml'\n",
    "\n",
    "# run the update yaml method to update desired key's values\n",
    "update_yaml(MODEL_CONFIG_PAIRS[MODEL], new_yaml_path, new_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcd4a3db-ea86-4f02-aee2-0743b09ee5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'category': 'transistor',\n",
      "             'center_crop': None,\n",
      "             'eval_batch_size': 16,\n",
      "             'format': 'mvtec',\n",
      "             'image_size': 256,\n",
      "             'name': 'mvtec',\n",
      "             'normalization': 'none',\n",
      "             'num_workers': 8,\n",
      "             'path': '/transitor/transitor',\n",
      "             'task': 'segmentation',\n",
      "             'test_split_mode': 'from_dir',\n",
      "             'test_split_ratio': 0.2,\n",
      "             'train_batch_size': 48,\n",
      "             'transform_config': {'eval': None, 'train': None},\n",
      "             'val_split_mode': 'same_as_test',\n",
      "             'val_split_ratio': 0.5},\n",
      " 'logging': {'log_graph': False, 'logger': []},\n",
      " 'metrics': {'image': ['F1Score', 'AUROC'],\n",
      "             'pixel': ['F1Score', 'AUROC'],\n",
      "             'threshold': {'manual_image': None,\n",
      "                           'manual_pixel': None,\n",
      "                           'method': 'adaptive'}},\n",
      " 'model': {'lr': 0.0001,\n",
      "           'model_size': 'medium',\n",
      "           'name': 'efficientad',\n",
      "           'normalization_method': 'min_max',\n",
      "           'padding': True,\n",
      "           'teacher_out_channels': 384,\n",
      "           'weight_decay': 1e-05},\n",
      " 'optimization': {'export_mode': None},\n",
      " 'project': {'path': './results', 'seed': 101},\n",
      " 'trainer': {'accelerator': 'auto',\n",
      "             'accumulate_grad_batches': 1,\n",
      "             'auto_lr_find': False,\n",
      "             'auto_scale_batch_size': False,\n",
      "             'benchmark': False,\n",
      "             'check_val_every_n_epoch': 1,\n",
      "             'default_root_dir': None,\n",
      "             'detect_anomaly': False,\n",
      "             'deterministic': False,\n",
      "             'devices': 1,\n",
      "             'enable_checkpointing': True,\n",
      "             'enable_model_summary': True,\n",
      "             'enable_progress_bar': True,\n",
      "             'fast_dev_run': False,\n",
      "             'gradient_clip_algorithm': 'norm',\n",
      "             'gradient_clip_val': 0,\n",
      "             'limit_predict_batches': 1.0,\n",
      "             'limit_test_batches': 1.0,\n",
      "             'limit_train_batches': 1.0,\n",
      "             'limit_val_batches': 1.0,\n",
      "             'log_every_n_steps': 50,\n",
      "             'max_epochs': 200,\n",
      "             'max_steps': -1,\n",
      "             'max_time': None,\n",
      "             'min_epochs': None,\n",
      "             'min_steps': None,\n",
      "             'move_metrics_to_cpu': False,\n",
      "             'multiple_trainloader_mode': 'max_size_cycle',\n",
      "             'num_nodes': 1,\n",
      "             'num_sanity_val_steps': 0,\n",
      "             'overfit_batches': 0.0,\n",
      "             'plugins': None,\n",
      "             'precision': 32,\n",
      "             'profiler': None,\n",
      "             'reload_dataloaders_every_n_epochs': 0,\n",
      "             'replace_sampler_ddp': True,\n",
      "             'strategy': None,\n",
      "             'sync_batchnorm': False,\n",
      "             'track_grad_norm': -1,\n",
      "             'val_check_interval': 1.0},\n",
      " 'visualization': {'image_save_path': None,\n",
      "                   'log_images': False,\n",
      "                   'mode': 'full',\n",
      "                   'save_images': True,\n",
      "                   'show_images': False}}\n"
     ]
    }
   ],
   "source": [
    "with open(new_yaml_path) as f:\n",
    "    updated_config = yaml.safe_load(f)\n",
    "pprint.pprint(updated_config) # check if upadted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38588cf-29d0-4c93-9157-3ab7fc65513e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
